{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook for RJMCMC Simulation Study (Two-Stage)\n",
    " This script orchestrates the full simulation study in a two-stage process:\n",
    "\n",
    " 1.  **Stage 1: Sensitivity Analysis**: Runs a streamlined simulation across a\n",
    "     grid of hyperparameters and delay scenarios to find the optimal settings.\n",
    "     This stage **only runs the proposed RJMCMC method** to save time.\n",
    " 2.  **Stage 2: Main Simulation**: Uses the optimal parameters found in Stage 1\n",
    "     to run a larger-scale simulation for final performance evaluation against\n",
    "     all benchmark methods.\n",
    " 3.  **Stage 3: Full Analysis**: Processes the results from both stages to\n",
    "     generate the sensitivity analysis figure and the final LaTeX summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Import project-specific modules\n",
    "from config import (\n",
    "    SCENARIOS, N_REPLICATIONS, SENSITIVITY_REPLICATIONS,\n",
    "    SENSITIVITY_GRID_PRIORS, DELAY_DIST_SENSITIVITY, SIGNAL_CACHE_DIR,\n",
    "    MAIN_RESULTS_DIR, SENSITIVITY_RESULTS_DIR, PLOTS_DIR\n",
    ")\n",
    "from data_generation import generate_dataset\n",
    "from methods import run_rjmcmc, run_pelt, run_binseg, run_rtacfr\n",
    "from analysis import full_analysis_workflow, find_optimal_hyperparameters, load_and_process_sensitivity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Simulation Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_worker(args):\n",
    "    \"\"\"A worker function to run a single simulation instance for any stage.\"\"\"\n",
    "    scenario_name, rep_idx, output_dir, params, run_benchmarks = args\n",
    "    scenario_config = SCENARIOS[scenario_name]\n",
    "    \n",
    "    # Generate a unique, descriptive filename for this run's checkpoint\n",
    "    filename_parts = [scenario_name.replace(' ', '_'), f\"rep{rep_idx}\"]\n",
    "    if 'PRIOR_K_GEOMETRIC_P' in params:\n",
    "        filename_parts.append(f\"p{params['PRIOR_K_GEOMETRIC_P']}\")\n",
    "    if 'PRIOR_THETA_SIGMA' in params:\n",
    "        filename_parts.append(f\"s{params['PRIOR_THETA_SIGMA']}\")\n",
    "    if 'DELAY_DIST_NAME' in params:\n",
    "        delay_short_name = params['DELAY_DIST_NAME'].split(' ')[0]\n",
    "        filename_parts.append(f\"delay_{delay_short_name}\")\n",
    "    filepath = os.path.join(output_dir, \"_\".join(filename_parts) + \".pkl\")\n",
    "\n",
    "    # Skip if this exact simulation has already been completed\n",
    "    if os.path.exists(filepath):\n",
    "        return f\"Skipping existing: {filepath}\"\n",
    "    \n",
    "    # Generate dataset, allowing for an override of the default delay distribution\n",
    "    delay_dist_override = params.get('DELAY_DIST', None)\n",
    "    data = generate_dataset(scenario_config, rep_idx, delay_dist_override=delay_dist_override)\n",
    "    \n",
    "    # Always run the proposed RJMCMC method.\n",
    "    # The `run_rjmcmc` function is now memory-efficient and always returns summaries.\n",
    "    rjmcmc_results = run_rjmcmc(data, \n",
    "                                p_geom=params.get('PRIOR_K_GEOMETRIC_P'), \n",
    "                                theta_sigma=params.get('PRIOR_THETA_SIGMA'))\n",
    "    \n",
    "    # Initialize results dictionary with the proposed method's output\n",
    "    results = {\n",
    "        'scenario': scenario_name,\n",
    "        'rep_idx': rep_idx,\n",
    "        'params': params,\n",
    "        'data': data,\n",
    "        'rjmcmc': rjmcmc_results\n",
    "    }\n",
    "    \n",
    "    # Conditionally run benchmark methods if requested (for the main simulation)\n",
    "    if run_benchmarks:\n",
    "        rtacfr_results = run_rtacfr(data, scenario_name, rep_idx)\n",
    "        pelt_results = run_pelt(data, scenario_name, rep_idx)\n",
    "        binseg_results = run_binseg(data, scenario_name, rep_idx)\n",
    "        results['rtacfr'] = rtacfr_results\n",
    "        results['pelt'] = pelt_results\n",
    "        results['binseg'] = binseg_results\n",
    "    \n",
    "    # Save the results to a pickle file\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "        \n",
    "    return f\"Completed: {filepath}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stage 1: Run Full Sensitivity Analysis (Proposed Method Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STAGE 1: Starting Full Sensitivity Analysis ---\n",
      "Running 1875 sensitivity simulations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensitivity Analysis: 100%|███████████████████████████████████████████████████████| 1875/1875 [00:04<00:00, 463.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STAGE 1: Sensitivity Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    os.makedirs(SENSITIVITY_RESULTS_DIR, exist_ok=True)\n",
    "    \n",
    "    print(\"--- STAGE 1: Starting Full Sensitivity Analysis ---\")\n",
    "    \n",
    "    # Create the grid of all combinations of hyperparameters for sensitivity check\n",
    "    p_geom_values = SENSITIVITY_GRID_PRIORS['PRIOR_K_GEOMETRIC_P']\n",
    "    theta_sigma_values = SENSITIVITY_GRID_PRIORS['PRIOR_THETA_SIGMA']\n",
    "    hyperparam_grid = list(itertools.product(p_geom_values, theta_sigma_values))\n",
    "    \n",
    "    tasks = []\n",
    "    # Iterate over each delay distribution setting, scenario, replication, and hyperparameter combo\n",
    "    for delay_name, delay_dist_obj in DELAY_DIST_SENSITIVITY.items():\n",
    "        for scenario_name in SCENARIOS:\n",
    "            for rep_idx in range(SENSITIVITY_REPLICATIONS):\n",
    "                for p_geom, theta_sigma in hyperparam_grid:\n",
    "                    params = {\n",
    "                        'PRIOR_K_GEOMETRIC_P': p_geom,\n",
    "                        'PRIOR_THETA_SIGMA': theta_sigma,\n",
    "                        'DELAY_DIST_NAME': delay_name,\n",
    "                        'DELAY_DIST': delay_dist_obj\n",
    "                    }\n",
    "                    # The `False` flag indicates not to run the benchmarks\n",
    "                    tasks.append((scenario_name, rep_idx, SENSITIVITY_RESULTS_DIR, params, False))\n",
    "\n",
    "    # Run all sensitivity analysis tasks in parallel using joblib\n",
    "    print(f\"Running {len(tasks)} sensitivity simulations...\")\n",
    "    Parallel(n_jobs=-1)(delayed(simulation_worker)(task) for task in tqdm(tasks, desc=\"Sensitivity Analysis\"))\n",
    "    \n",
    "    print(\"--- STAGE 1: Sensitivity Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stage 2: Run Main Simulation (All Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sensitivity results from: results/sensitivity: 100%|██████████████████████| 9115/9115 [00:11<00:00, 797.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimal Hyperparameter Selection ---\n",
      "Selected from 'Perfectly Matched Delay' scenario.\n",
      "Optimal p_geom: 0.7\n",
      "Optimal theta_sigma: 1.0\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "--- STAGE 2: Starting Main Simulation with Optimal Parameters ---\n",
      "Running 50 main simulations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main Simulation: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 14462.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STAGE 2: Main Simulation Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # First, find the optimal parameters by analyzing the results from Stage 1\n",
    "    df_sens = load_and_process_sensitivity_results(SENSITIVITY_RESULTS_DIR)\n",
    "    optimal_params = find_optimal_hyperparameters(df_sens)\n",
    "\n",
    "    # Now, run the main, larger-scale simulation using only these optimal parameters\n",
    "    os.makedirs(MAIN_RESULTS_DIR, exist_ok=True)\n",
    "    os.makedirs(SIGNAL_CACHE_DIR, exist_ok=True)\n",
    "    print(\"\\n--- STAGE 2: Starting Main Simulation with Optimal Parameters ---\")\n",
    "    \n",
    "    main_tasks = []\n",
    "    for scenario_name in SCENARIOS:\n",
    "        for rep_idx in range(N_REPLICATIONS):\n",
    "            # The `True` flag indicates that benchmarks should be run\n",
    "            main_tasks.append((scenario_name, rep_idx, MAIN_RESULTS_DIR, optimal_params, True))\n",
    "            \n",
    "    # Run all main simulation tasks in parallel using joblib\n",
    "    print(f\"Running {len(main_tasks)} main simulations...\")\n",
    "    Parallel(n_jobs=-1)(delayed(simulation_worker)(task) for task in tqdm(main_tasks, desc=\"Main Simulation\"))\n",
    "        \n",
    "    print(\"--- STAGE 2: Main Simulation Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stage 3: Run Full Analysis and Generate Final Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STAGE 3: Running Full Analysis Workflow ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sensitivity results from: results/sensitivity: 100%|█████████████████████| 9115/9115 [00:07<00:00, 1160.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity analysis heatmap grid saved at: plots\\sensitivity_analysis_heatmap_grid.pdf\n",
      "\n",
      "--- Optimal Hyperparameter Selection ---\n",
      "Selected from 'Perfectly Matched Delay' scenario.\n",
      "Optimal p_geom: 0.7\n",
      "Optimal theta_sigma: 1.0\n",
      "--------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading main results from: results/main: 100%|██████████████████████████████████████| 100/100 [00:00<00:00, 563.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main results LaTeX table saved at: plots\\main_results_table.tex\n",
      "Publication figure saved at: plots\\publication_figure.pdf\n",
      "\n",
      "--- Analysis Complete ---\n",
      "\n",
      "--- All simulations and analyses are complete. ---\n",
      "\n",
      "Final outputs have been saved in the 'plots' directory:\n",
      "- Publication Figure: publication_figure.pdf\n",
      "- Sensitivity Heatmap: sensitivity_analysis_heatmap_grid.pdf\n",
      "- Main Results Table: main_results_table.tex\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"\\n--- STAGE 3: Running Full Analysis Workflow ---\")\n",
    "    \n",
    "    # This single function handles all analysis and generation of outputs (figures and tables)\n",
    "    full_analysis_workflow()\n",
    "    \n",
    "    print(\"\\n--- All simulations and analyses are complete. ---\")\n",
    "    pub_fig_path = os.path.join(PLOTS_DIR, \"publication_figure.pdf\")\n",
    "    sens_fig_path = os.path.join(PLOTS_DIR, \"sensitivity_analysis_heatmap_grid.pdf\")\n",
    "    table_path = os.path.join(PLOTS_DIR, \"main_results_table.tex\")\n",
    "    \n",
    "    print(f\"\\nFinal outputs have been saved in the '{PLOTS_DIR}' directory:\")\n",
    "    print(f\"- Publication Figure: {os.path.basename(pub_fig_path)}\")\n",
    "    print(f\"- Sensitivity Heatmap: {os.path.basename(sens_fig_path)}\")\n",
    "    print(f\"- Main Results Table: {os.path.basename(table_path)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
